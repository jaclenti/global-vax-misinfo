{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import community as nx_comm\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from python_paris import paris\n",
    "from sknetwork.hierarchy import cut_straight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Clustering\n",
    "From the (weighted) cosharing and retweets edgelists in folder_EU_AM, we detect the communities with hierarchical clustering.\n",
    "For each country and period, for CO and RT edgelist:\n",
    "- With Paris we create the dendrogram\n",
    "- Compare the partitions obtained with the first 5 cuts, keep the partition with highest modularity\n",
    "- If 90% of nodes are in the same community, study the following 5 cuts, and repeat the procedure until the largest community covers <90% of nodes\n",
    "- assign users to the communities\n",
    "- Save the communities in the same folder in the format IT_it_period1_RT_communities.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = {\"period1\": [\"201910\",\"201911\",\"201912\"],\n",
    "           \"period2\": [\"202007\",\"202008\",\"202009\"], \n",
    "           \"period3\": [\"202010\",\"202011\",\"202012\"], \n",
    "           \"period4\":  [\"202101\",\"202102\",\"202103\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_EU_AM = \"/data/public/jlenti/multilang-vax/EuropeAmerica_RTCO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BR</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AR</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GB</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ES</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country lang\n",
       "0      US   en\n",
       "1      BR   pt\n",
       "2      AR   es\n",
       "3      GB   en\n",
       "4      ES   es"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframes with all the pairs lang-countries, with the selected countries\n",
    "selected_pairs = pd.read_csv(\"/home/jlenti/Files/country_langs_selected_2104.csv\", index_col = 0)\n",
    "selected_pairs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a dendrogram and a cutoff, return a dataframe with columns user - community, with the communities obtained at the given cut      \n",
    "def nodes_community_dendro(dendro, n, G):  \n",
    "    nodes_G = list(G.nodes)\n",
    "     #flatten the dendrogram, with a list of labels, associating nodes to communities\n",
    "    l = cut_straight(dendro, n_clusters = n)\n",
    "     #transform in l + 1 in order to start from community 1 (instead of commuity 0)\n",
    "    df = pd.DataFrame({\"user\": nodes_G, \"community\": l + 1})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a dendrogram from a hierarchical clustering, return (and print) the modularities obtained at different cuts. cuts is the list of cutoff heights we want to compare \n",
    "def dendrogram_modularity(dendro, G, cuts, plot = True):    \n",
    "    nodes_G = list(G.nodes)\n",
    "    modularities = {}                                                   \n",
    "    for n in cuts:                                                                              \n",
    "        coms = []\n",
    "        l = cut_straight(dendro, n_clusters = n)\n",
    "        for i in range(n):\n",
    "            ind_i = list(np.where(l == i)[0])\n",
    "            coms.append([nodes_G[k] for k in ind_i])\n",
    "        modularities[n] = nx_comm.modularity(G, coms)\n",
    "    return modularities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a graph and its hierarchical clustering, compute the modularity for all the cuts in cuts\n",
    "#pick the cutoff with highest modularity\n",
    "#return df with nodes labels and modularity selected\n",
    "def best_modularity_community_label(dendro, G, cuts):\n",
    "    #compute all the modularities for all the cuts in cuts\n",
    "    mods = dendrogram_modularity(dendro, G, cuts, plot = False)\n",
    "    #cut that gives the highest modularity\n",
    "    best_cut = max(mods, key = mods.get)\n",
    "    #label the nodes\n",
    "    community_df = nodes_community_dendro(dendro, best_cut, G)\n",
    "    return (community_df, mods[best_cut])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: the graph, the cuts compared in the dendrogram and information about the folder\n",
    "#build the dendrogram with paris. If it does not work, try paris from a different package, and ward (save used algorithm).\n",
    "#best_modularity_community_label find the best cutoff (highest modularity), returns community labelling and modularity\n",
    "#save modularity, used algorithm and community label\n",
    "#when paris return only one big community try the 5 higher cuts!\n",
    "def save_communities_modularity_paris(G, folder, country, lang, period, layer, cuts = np.arange(2,6)):    \n",
    "        #need undirected graph\n",
    "    try:\n",
    "        dendro = paris(nx.Graph(G))\n",
    "        communities, modularity = best_modularity_community_label(dendro, G, cuts)\n",
    "        algo = \"paris\"\n",
    "    except:\n",
    "        #if paris and ward do not work (too small graphs), save null data in the predefined folders\n",
    "        algo, modularity = \"null\", -1\n",
    "        communities = pd.DataFrame({\"user\": [], \"community\": []})\n",
    "        print(period, \"null\")\n",
    "                \n",
    "    if (len(communities) > 0) & ((communities[\"community\"].value_counts() / len(communities)).max() > 0.9):\n",
    "            print(\"next cuts\")\n",
    "            save_communities_modularity_paris(G, folder, country, lang, period, layer, cuts + 5)\n",
    "        \n",
    "    else:\n",
    "        #save data in a way such as\n",
    "        #/data/public/jlenti/multilang-vax/multilayer_RT_CO/IT/period1/IT_it_period1_community_RT.csv.gz\n",
    "        #where folder = /data/public/jlenti/multilang-vax/multilayer_RT_CO/\n",
    "        a = 0\n",
    "        \n",
    "        #with open(\"/\".join([folder, period, \"_\".join([country, lang, period, layer, \"modularity.txt\"])]), \"w\") as f:\n",
    "        #    f.write(str(modularity))\n",
    "        #with open(\"/\".join([folder, period, \"_\".join([country, lang, period, layer, \"algo.txt\"])]), \"w\") as f:\n",
    "        #    f.write(str(algo))\n",
    "        #communities.to_csv(\"/\".join([folder, period,  \"_\".join([country, lang, period, layer, \"communities.csv.gz\"])]),\n",
    "        #                   compression = \"gzip\", index = False)\n",
    "        return communities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = \"RT\"\n",
    "period = \"period1\"\n",
    "country, lang = \"IT\", \"it\"\n",
    "edges = pd.read_csv(sorted(glob(\"/\".join([folder_EU_AM, period, \"*\".join([country, layer, \"edg\", \"\"])])))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_full = nx.from_pandas_edgelist(edges, \n",
    "                                 source = edges.columns[0],\n",
    "                                 target = edges.columns[1], \n",
    "                                 edge_attr = \"weight\")\n",
    "#need to extract giant component (while in RT and CO we had only data in giant component)\n",
    "G = G_full.subgraph(max(nx.connected_components(G_full), key = len))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "coms = save_communities_modularity_paris(G, \"\", country, lang, period, layer, cuts = np.arange(2,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>community</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000Salvatore</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CriticaScient</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DavideFalchieri</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FmMosca</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GavinoSanna1967</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              user  community\n",
       "0     000Salvatore          1\n",
       "1    CriticaScient          1\n",
       "2  DavideFalchieri          1\n",
       "3          FmMosca          1\n",
       "4  GavinoSanna1967          1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RT Communities - All countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for country in countries \n",
    "#-extract edgelist files\n",
    "#-build graph (giant component)\n",
    "#-save communities\n",
    "layer = \"RT\"\n",
    "\n",
    "for period in periods:\n",
    "    for _, (country, lang) in selected_pairs.iterrows():\n",
    "        edges = pd.read_csv(sorted(glob(\"/\".join([folder_EU_AM, period, \"*\".join([country, layer, \"edg\", \"\"])])))[0])        \n",
    "        \n",
    "        G_full = nx.from_pandas_edgelist(edges, \n",
    "                                         source = \"user_screen_name\",\n",
    "                                         target = \"RT_user_screen_name\",\n",
    "                                         edge_attr = \"weight\")\n",
    "        #need to extract giant component (while in RT and CO we had only data in giant component)\n",
    "        G = G_full.subgraph(max(nx.connected_components(G_full), key = len))\n",
    "        \n",
    "        with open(\"/\".join([folder_0612, period, \"_\".join([country, lang, period, layer, \"n_nodes.txt\"])]), \"w\") as f:\n",
    "            f.write(\" \".join([str(G_full.number_of_nodes()), str(G.number_of_nodes())]))\n",
    "            \n",
    "        #find communities and save\n",
    "        save_communities_modularity_paris(G, folder_EU_AM, country, lang, period, layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CO Communities - All countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for country in countries \n",
    "#-extract edgelist files\n",
    "#-build graph (giant component)\n",
    "#-save communities\n",
    "layer = \"CO\"\n",
    "\n",
    "for period in periods:\n",
    "    for _, (country, lang) in selected_pairs.iterrows():\n",
    "        edges = pd.read_csv(sorted(glob(\"/\".join([folder_EU_AM, period, \"*\".join([country, layer, \"edg\", \"\"])])))[0])        \n",
    "        \n",
    "        G_full = nx.from_pandas_edgelist(edges, \n",
    "                                         source = \"user1\",\n",
    "                                         target = \"user2\",\n",
    "                                         edge_attr = \"weight\")\n",
    "        #need to extract giant component (while in RT and CO we had only data in giant component)\n",
    "        G = G_full.subgraph(max(nx.connected_components(G_full), key = len))\n",
    "        \n",
    "        with open(\"/\".join([folder_0612, period, \"_\".join([country, lang, period, layer, \"n_nodes.txt\"])]), \"w\") as f:\n",
    "            f.write(\" \".join([str(G_full.number_of_nodes()), str(G.number_of_nodes())]))\n",
    "            \n",
    "        #find communities and save\n",
    "        save_communities_modularity_paris(G, folder_EU_AM, country, lang, period, layer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
