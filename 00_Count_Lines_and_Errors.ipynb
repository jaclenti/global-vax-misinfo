{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON Errors Analysis\n",
    "In this notebook we analyze which files are correctly formatted, comparing the periods and languages.\n",
    "- Correct files are in .json\n",
    "- Some files are not json, so they return error during the opening of the json (function json.loads())\n",
    "- Some files retrieve some Twitter errors. json.loads() works, but they return some number such as, 420, 400. To find these. So I consider correct only the files that are loadable and have the entry \"created_at\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import gzip\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder with all data divided by language\n",
    "files = sorted(glob(\"/data/fast/public/collections/multilang/DATA/vaccine/*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_at': 'Mon Oct 14 04:10:06 +0000 2019',\n",
       " 'id': 1183595812208762880,\n",
       " 'id_str': '1183595812208762880',\n",
       " 'text': '@GurkaynakGonenc @DrMkoksal Grip aşısı ne yazık ki, küçük bir kaç grup için ücretsiz.',\n",
       " 'display_text_range': [28, 85],\n",
       " 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       " 'truncated': False,\n",
       " 'in_reply_to_status_id': 1183499690932948992,\n",
       " 'in_reply_to_status_id_str': '1183499690932948992',\n",
       " 'in_reply_to_user_id': 2827010891,\n",
       " 'in_reply_to_user_id_str': '2827010891',\n",
       " 'in_reply_to_screen_name': 'GurkaynakGonenc',\n",
       " 'user': {'id': 1850791254,\n",
       "  'id_str': '1850791254',\n",
       "  'name': 'Beyhan Bulgurlu',\n",
       "  'screen_name': 'beyhangoksan',\n",
       "  'location': None,\n",
       "  'url': None,\n",
       "  'description': None,\n",
       "  'translator_type': 'none',\n",
       "  'protected': False,\n",
       "  'verified': False,\n",
       "  'followers_count': 173,\n",
       "  'friends_count': 375,\n",
       "  'listed_count': 2,\n",
       "  'favourites_count': 6183,\n",
       "  'statuses_count': 12066,\n",
       "  'created_at': 'Tue Sep 10 08:29:51 +0000 2013',\n",
       "  'utc_offset': None,\n",
       "  'time_zone': None,\n",
       "  'geo_enabled': True,\n",
       "  'lang': None,\n",
       "  'contributors_enabled': False,\n",
       "  'is_translator': False,\n",
       "  'profile_background_color': 'C0DEED',\n",
       "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_tile': False,\n",
       "  'profile_link_color': '1DA1F2',\n",
       "  'profile_sidebar_border_color': 'C0DEED',\n",
       "  'profile_sidebar_fill_color': 'DDEEF6',\n",
       "  'profile_text_color': '333333',\n",
       "  'profile_use_background_image': True,\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/433589219286863872/aY_H7wGq_normal.jpeg',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/433589219286863872/aY_H7wGq_normal.jpeg',\n",
       "  'default_profile': True,\n",
       "  'default_profile_image': False,\n",
       "  'following': None,\n",
       "  'follow_request_sent': None,\n",
       "  'notifications': None},\n",
       " 'geo': None,\n",
       " 'coordinates': None,\n",
       " 'place': None,\n",
       " 'contributors': None,\n",
       " 'is_quote_status': False,\n",
       " 'quote_count': 0,\n",
       " 'reply_count': 0,\n",
       " 'retweet_count': 0,\n",
       " 'favorite_count': 0,\n",
       " 'entities': {'hashtags': [],\n",
       "  'urls': [],\n",
       "  'user_mentions': [{'screen_name': 'GurkaynakGonenc',\n",
       "    'name': 'Gönenç Gürkaynak',\n",
       "    'id': 2827010891,\n",
       "    'id_str': '2827010891',\n",
       "    'indices': [0, 16]},\n",
       "   {'screen_name': 'DrMkoksal',\n",
       "    'name': 'Av. Doç. Dr. Mehmet Köksal',\n",
       "    'id': 496057754,\n",
       "    'id_str': '496057754',\n",
       "    'indices': [17, 27]}],\n",
       "  'symbols': []},\n",
       " 'favorited': False,\n",
       " 'retweeted': False,\n",
       " 'filter_level': 'low',\n",
       " 'lang': 'tr',\n",
       " 'timestamp_ms': '1571026206434'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gzip.open(files[240], \"rt\") as f:\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        break\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mon Oct 14 04:10:06 +0000 2019'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet[\"created_at\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error with json.loads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-028b897ba4d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rt\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "with gzip.open(files[2000], \"rt\") as f:\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        break\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Traceback (most recent call last):\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gzip.open(files[2540], \"rt\") as f:\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        break\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-e13b7ebc6b58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"created_at\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "tweet[\"created_at\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One File Example\n",
    "Let us count the number of json lines and errors for one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2540\n",
    "\n",
    "json_files, json_errors, twitter_errors = 0, 0, 0\n",
    "file = files[k]\n",
    "lang = file.split(\"_\")[1].split(\".\")[0].split(\"-\")\n",
    "day = file.split(\"/\")[-1].split(\"_\")[0]\n",
    "month = day[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(files[k], \"rt\") as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            tweet = json.loads(line)\n",
    "            try:\n",
    "                u = tweet[\"created_at\"]\n",
    "                json_files += 1\n",
    "            except:\n",
    "                twitter_errors += 1\n",
    "        except:\n",
    "            json_errors += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang                  [hu]\n",
       "day               20200717\n",
       "month               202007\n",
       "json_lines               5\n",
       "json_errors              0\n",
       "twitter_errors         133\n",
       "dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([lang, day, month, json_files, json_errors, twitter_errors],\n",
    "          index = [\"lang\", \"day\", \"month\", \"json_lines\", \"json_errors\", \"twitter_errors\"]\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"count_lines = []\n",
    "\n",
    "for file in files:\n",
    "    json_files, json_errors, twitter_errors = 0,0,0\n",
    "    lang = file.split(\"_\")[1].split(\".\")[0].split(\"-\")\n",
    "    day = file.split(\"/\")[-1].split(\"_\")[0]\n",
    "    month = day[:6]\n",
    "    with gzip.open(file, \"rt\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                tweet = json.loads(line)\n",
    "                try:\n",
    "                    u = tweet[\"created_at\"]\n",
    "                    json_files += 1\n",
    "                except:\n",
    "                    twitter_errors += 1\n",
    "            except:\n",
    "                json_errors += 1\n",
    "    count_lines.append([lang, day, month, json_files, json_errors, twitter_errors])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_lines = []\n",
    "\n",
    "for file in files:\n",
    "    json_files, json_errors, twitter_errors = 0,0,0\n",
    "    lang = file.split(\"_\")[1].split(\".\")[0].split(\"-\")\n",
    "    day = file.split(\"/\")[-1].split(\"_\")[0]\n",
    "    month = day[:6]\n",
    "    with gzip.open(file, \"rt\") as f:\n",
    "        try:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    tweet = json.loads(line)\n",
    "                    try:\n",
    "                        u = tweet[\"created_at\"]\n",
    "                        json_files += 1\n",
    "                    except:\n",
    "                        twitter_errors += 1\n",
    "                except:\n",
    "                    json_errors += 1\n",
    "        except:\n",
    "            json_errors += 1\n",
    "                \n",
    "    count_lines.append([lang, day, month, json_files, json_errors, twitter_errors])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(count_lines, columns = [\"lang\", \"day\", \"month\", \"json_lines\", \"json_errors\", \"twitter_errors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>json_lines</th>\n",
       "      <th>json_errors</th>\n",
       "      <th>twitter_errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[bg, pl, pt, fr]</td>\n",
       "      <td>20190904</td>\n",
       "      <td>201909</td>\n",
       "      <td>7283</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[bg, fi, el, cs]</td>\n",
       "      <td>20190905</td>\n",
       "      <td>201909</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bg, pl, pt, fr]</td>\n",
       "      <td>20190905</td>\n",
       "      <td>201909</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[en]</td>\n",
       "      <td>20190905</td>\n",
       "      <td>201909</td>\n",
       "      <td>53312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[es]</td>\n",
       "      <td>20190905</td>\n",
       "      <td>201909</td>\n",
       "      <td>16773</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16316</th>\n",
       "      <td>[ro]</td>\n",
       "      <td>20220606</td>\n",
       "      <td>202206</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16317</th>\n",
       "      <td>[ru]</td>\n",
       "      <td>20220606</td>\n",
       "      <td>202206</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16318</th>\n",
       "      <td>[sk]</td>\n",
       "      <td>20220606</td>\n",
       "      <td>202206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16319</th>\n",
       "      <td>[sv]</td>\n",
       "      <td>20220606</td>\n",
       "      <td>202206</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16320</th>\n",
       "      <td>[tr]</td>\n",
       "      <td>20220606</td>\n",
       "      <td>202206</td>\n",
       "      <td>5016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16321 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   lang       day   month  json_lines  json_errors  \\\n",
       "0      [bg, pl, pt, fr]  20190904  201909        7283            0   \n",
       "1      [bg, fi, el, cs]  20190905  201909          29            0   \n",
       "2      [bg, pl, pt, fr]  20190905  201909         329            0   \n",
       "3                  [en]  20190905  201909       53312            0   \n",
       "4                  [es]  20190905  201909       16773            0   \n",
       "...                 ...       ...     ...         ...          ...   \n",
       "16316              [ro]  20220606  202206          71            0   \n",
       "16317              [ru]  20220606  202206         415            0   \n",
       "16318              [sk]  20220606  202206           0            0   \n",
       "16319              [sv]  20220606  202206         285            0   \n",
       "16320              [tr]  20220606  202206        5016            0   \n",
       "\n",
       "       twitter_errors  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   1  \n",
       "3                   0  \n",
       "4                   0  \n",
       "...               ...  \n",
       "16316               0  \n",
       "16317               0  \n",
       "16318               0  \n",
       "16319               0  \n",
       "16320               0  \n",
       "\n",
       "[16321 rows x 6 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"/home/jlenti/Files/count_lines_and_errors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
